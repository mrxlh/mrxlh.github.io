---
title: 分词器的内部组成与内置分词器
date: 2020-02-02 17:07:11
tags: ['Elasticsearch']
categories: Elasticsearch
---

#### 分词器的内部组成与内置分词器

##### 1. 分词器

切分词语，normalization（提升recall召回率）

给出一个句子，然后将这段句子拆分成一个一个的单个的单词，同时对每个单词进行normalization（时态转换，单复数转换），分词器
recall(召回率)：搜索的时候，增加能够搜索到的结果的数量

character filter：

在一段文本进行分词之前，先进行预处理，比如说最常见的就是，过滤html标签（<span>hello<span> --> hello），& --> and（I&you --> I and you）
tokenizer：分词，hello you and me --> hello, you, and, me
token filter：lowercase，stop word，synonymom，dogs --> dog，liked --> like，Tom --> tom，a/the/an --> 干掉 停用词，mother --> mom，small --> little

分词器，是将一段文本进行各种处理，最后处理好的结果才会拿去建立倒排索引

##### 2. 内置分词器的介绍

Set the shape to semi-transparent by calling set_trans(5)

###### 1.standard analyzer

standard analyzer：set, the, shape, to, semi, transparent, by, calling, set_trans, 5（默认的是standard）

 特性: 按词切分,支持多语言;小写处理

###### 2.simple analyzer

simple analyzer：set, the, shape, to, semi, transparent, by, calling, set, trans

特性: 按照非字母切分,小写处理

###### 3. stop  analyzer

stop  analyzer: 相比 simple analyzer 多了Stop Work处理

Stop Word: 值语气助词等修饰性的词语 ,eg : the an a

###### 4. whitespace analyzer

whitespace analyzer：Set, the, shape, to, semi-transparent, by, calling, set_trans(5)

###### 5. language analyzer

language analyzer（特定的语言的分词器，比如说，english，英语分词器）：set, shape, semi, transpar, call, set_tran, 5

###### 6.  keywork Analyzer

特性: 不分词,直接将输入作为一个单词输出  (不想对文本进行分词)

######  7. pattern analyzer

特性: 通过正则表达式自定义分隔符

默认是 \W+,即非字词的符号作为分隔符











